import torch
import torch.nn as nn
from models.skeleton import SkeletonConv
from models.utils import GAN_loss, ImagePool, VeloLabelConsistencyLoss, RecLoss, get_layered_mask
import functools


class Conv1dModel(nn.Module):
    def __init__(self, channels, kernel_size, padding=-1, last_active='None', padding_mode='zeros', batch_norm=False,
                 skeleton_aware=False, neighbour_list=None, activation='LeakyReLU'):
        super(Conv1dModel, self).__init__()
        conv1d = functools.partial(SkeletonConv, neighbour_list=neighbour_list, joint_num=len(neighbour_list)) \
            if skeleton_aware else nn.Conv1d
        self.cond_encoder = nn.Conv1d(in_channels=3, out_channels=len(neighbour_list)*6, kernel_size=1)
        self.refine_encoder = nn.Conv1d(in_channels=len(neighbour_list)*6+3, out_channels=len(neighbour_list)*6, kernel_size=1)
        if padding == -1:
            if kernel_size % 2 == 0:
                raise Exception('Only support odd kernel size for now')
            padding = (kernel_size - 1) // 2
        self.layers = nn.ModuleList()
        for i in range(len(channels) - 1):
            in_c = channels[i]
            out_c = channels[i + 1]
            if i == len(channels) - 2 and out_c == 1:
                conv1d = nn.Conv1d
            bias = not batch_norm
            if i == len(channels) - 2:
                bias = True
            seq = [conv1d(in_channels=in_c, out_channels=out_c, kernel_size=kernel_size,
                          padding=padding, padding_mode=padding_mode, bias=bias)]
            if i < len(channels) - 2:
                if batch_norm:
                    seq.append(nn.BatchNorm1d(num_features=out_c))

                if activation == 'LeakyReLU':
                    seq.append(nn.LeakyReLU(negative_slope=0.2, inplace=True))
                elif activation == 'ReLU':
                    seq.append(nn.ReLU(inplace=True))
                else:
                    raise Exception('Unknown activation')
            else:
                if last_active is not None:
                    seq.append(last_active)
            self.layers.append(nn.Sequential(*seq))
        self.output = None
    def forward(self, input, prev_img=None, labels=None, cond=None, cond_requires_mask=False, disc=False):
        if labels is not None : 
            
            res_cond = self.cond_encoder(labels)
            inputs = input+res_cond
            # inputs = inputs
            # inputs = torch.cat([input, labels],dim=1)
            # inputs =self.refine_encoder(inputs)
        
        for idx, layer in enumerate(self.layers) :
                inputs = layer(inputs)
            # for sub_layer in layer.children():
            #     if isinstance(sub_layer, SkeletonConv):
            #         is_skelconv = True 
            #         break
            #     else :
            #         is_skelconv = False
            # if is_skelconv : 
            #     input = layer(inputs)
            # else :                 
            #     inputs = input
            #     input = layer(inputs)
            # inputs = input, labels
        self.output = inputs
        return self.output


class GAN_model:
    def __init__(self, gen: nn.Module, disc: nn.Module, args, dataset):
        self.gen = gen
        self.disc = disc
        self.optimizerG = torch.optim.Adam(gen.parameters(), lr=args.lr_g)
        self.optimizerD = torch.optim.Adam(disc.parameters(), lr=args.lr_d)
        self.fake_pool = ImagePool(50)
        self.criterion_gan = GAN_loss(args.gan_mode).to(args.device)
        # self.criterion_consistency = VeloLabelConsistencyLoss(dataset, args.detach_label, args.use_sigmoid, args.use_6d_fk).to(args.device)
        self.criterion_rec = RecLoss(dataset, False, args.rec_loss_type)
        self.gan_mode = args.gan_mode
        self.fake_res = None
        self.device = torch.device(args.device)
        self.loss_D = torch.tensor(0.)
        self.loss_G = torch.tensor(0.)
        self.loss_gp = torch.tensor(0.)
        self.loss_rec = torch.tensor(0.)
        self.loss_consistency = torch.tensor(0.)
        self.loss_G_total = torch.tensor(0.)
        self.loss_names = ['loss_D', 'loss_G', 'loss_gp', 'loss_rec', 'loss_G_total']
        self.args = args

    def disc_requires_grad_(self, requires_grad):
        for para in self.disc.parameters():
            para.requires_grad = requires_grad
    def backward_D_basic(self, netD, real, fake, real_labels):
        """Calculate GAN loss for the discriminator
        Parameters:
            netD (network)      -- the discriminator D
            real (tensor array) -- real images
            fake (tensor array) -- images generated by a generator
        Return the discriminator loss.
        We also call loss_D.backward() to calculate the gradients.
        """
        # Real
        pred_real = netD(real, labels=real_labels.detach())
        loss_D_real = self.criterion_gan(pred_real, True)
        # Fake
        pred_fake = netD(fake.detach(), labels=real_labels.detach())
        loss_D_fake = self.criterion_gan(pred_fake, False)
        # Combined loss and calculate gradients
        loss_D = (loss_D_real + loss_D_fake) * 0.5
        loss_D.backward()
        return loss_D

    def backward_D(self):
        fake = self.fake_pool.query(self.fake_res.detach())
        self.loss_D = self.backward_D_basic(self.disc, self.real_res, fake, self.real_labels)

        if self.gan_mode == 'wgan-gp':
            alpha = torch.rand((1,), device=self.device)
            interpolates = alpha * self.real_res + ((1 - alpha) * self.fake_res.detach())
            interpolates.requires_grad_(True)

            # disc_interpolates = self.disc(interpolates, labels=self.real_labels.detach())
            disc_interpolates = self.disc(interpolates, labels=self.real_labels.detach())

            gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,
                                            grad_outputs=torch.ones_like(disc_interpolates),
                                            create_graph=True, retain_graph=True, only_inputs=True)[0]
            gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
            gradient_penalty_back = gradient_penalty * self.args.lambda_gp
            gradient_penalty_back.backward()
            self.loss_gp = gradient_penalty
        self.loss_gp = 0 
    def backward_G(self):
        pred_fake = self.disc(self.fake_res, labels=self.real_labels.detach())
        self.loss_G = self.criterion_gan(pred_fake, True)
        # self.loss_consistency = self.criterion_consistency(self.fake_res) if self.args.contact else torch.tensor(0.)
        loss_total = self.loss_G 
                    #  self.loss_consistency * self.args.lambda_consistency
        self.loss_G_total = loss_total
        loss_total.backward(retain_graph=True)
    def forward(self, noise, real, img_base=0, cond=None, labels=None):
        if cond is not None:
            self.delta = self.gen(noise + img_base, img_base, cond=cond)
        else:
            self.delta = self.gen(noise + img_base, img_base, labels=labels.clone().detach())
        self.fake_res = self.delta + img_base
        # self.fake_res_label = self.real_labels + img_base
        self.fake_res_label = labels.clone().detach()
        self.real_res = real

    def forward_proxy(self, real, img_base=0, real_labels=None):
        """
        In new joint training implementation, the forward function for GAN_model will no longer be called.
        This is a proxy function to retrieve essential properties needed for the backward step.
        Those properties were stored by forward function.
        """
        assert real.shape[-1] == img_base.shape[-1]
        self.delta = self.gen.output
        self.real_res = real
        self.real_labels = real_labels
        self.fake_res = self.delta + img_base
    
    def optimize_parameters(self, gen=True, disc=True, rec=False):

        if self.args.no_gan:
            gen = False
            disc = False
        if gen:
            print(1)
            self.disc_requires_grad_(False)
            self.optimizerG.zero_grad()
            self.backward_G()
            self.optimizerG.step()
            print(2)
        if disc:
            print(3)
            self.disc_requires_grad_(True)
            self.optimizerD.zero_grad()
            self.backward_D()
            self.optimizerD.step()
            print(4)
        if rec:
            print(5)
            self.optimizerG.zero_grad()
            self.loss_rec = self.criterion_rec(self.fake_res, self.real_res)
            loss_rec_back = self.loss_rec * self.args.lambda_rec
            loss_rec_back.backward(retain_graph=True)
            self.optimizerG.step()
            print(6)
                
class LayeredModel(nn.Module):
    def __init__(self, args, regular: Conv1dModel, n_rot=None):
        super(LayeredModel, self).__init__()
        self.layers = nn.ModuleList()
        self.layers.append(regular)
        self.regular = regular

        self.layer_mask = get_layered_mask(args.conditional_mode, n_rot)
        self.args = args

        self.res_layered = None
        self.res_regular = None

    def forward(self, **kw):
        raise Exception('Not implemented')


class   LayeredGenerator(LayeredModel):
    def __init__(self, args, regular: Conv1dModel, n_rot=None, default_requires_mask=False):
        super(LayeredGenerator, self).__init__(args, regular, n_rot)
        self.default_requires_mask = default_requires_mask

    def forward(self, input, prev_img, cond=None, cond_requires_mask=None):
        """
        :param input: random noise + prev_img
        :param prev_img: upsampled image from previous layer (blurred)
        :param cond: condition on this layer (sharpe, from this level)
        :param cond_requires_mask: if condition is from a full animation (if need to take out part of it)
        :return: residual
        """
        if cond_requires_mask is None:
            cond_requires_mask = self.default_requires_mask
        if not isinstance(prev_img, torch.Tensor):
            val = prev_img
            prev_img = torch.empty_like(input)
            prev_img.fill_(val)
        if cond is None:
            raise Exception('Condition is required for conditional generator')
        else:
            if cond_requires_mask:
                cond = cond[:, self.layer_mask]
            self.res_layered = cond - prev_img[:, self.layer_mask]
        input[:, self.layer_mask] = self.res_layered + prev_img[:, self.layer_mask]
        self.res_regular = self.regular(input)
        self.res_regular[:, self.layer_mask] = self.res_layered
        self.output = self.regular.output
        return self.res_regular
